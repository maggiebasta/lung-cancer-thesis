{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "from skimage import io\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    img_to_array,\n",
    "    load_img\n",
    ")\n",
    "\n",
    "from data_generator_3d import *\n",
    "from cnn_baseline import *\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "#     rotation_range=5,\n",
    "    rescale=1./255,\n",
    "    shear_range=.1,\n",
    "#     zoom_range=.1,\n",
    "#     brightness_range=[.85, 1.0],\n",
    "#     zca_whitening=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    height_shift_range=5,\n",
    "    width_shift_range=5,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "label_generator = ImageDataGenerator(\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "# train_generator = image_generator.flow_from_directory(\n",
    "#     directory=\"data/nlst_train/image_full\",\n",
    "#     color_mode=\"grayscale\",\n",
    "#     target_size=(256, 256),\n",
    "#     batch_size=12,\n",
    "#     class_mode=\"binary\",\n",
    "#     shuffle=True,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# train_generator = image_generator.flow_from_directory(\n",
    "#     directory=\"data/nlst_train/image_roi_2d\",\n",
    "#     color_mode=\"grayscale\",\n",
    "#     target_size=(32, 32),\n",
    "#     batch_size=16,\n",
    "#     class_mode=\"binary\",\n",
    "#     shuffle=True,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "train_generator = generator(\n",
    "    base_directory='data/nlst_train/image_roi_3d',\n",
    "    input_gen=image_generator,\n",
    "    target_gen=label_generator,\n",
    "    batch_sz=1\n",
    "    \n",
    ")\n",
    "\n",
    "val_generator = generator(\n",
    "    base_directory='data/nlst_val/image_roi_3d',\n",
    "    input_gen=image_generator,\n",
    "    target_gen=label_generator,\n",
    "    batch_sz=1\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA54AAADjCAYAAADt28tlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3dty49YVhGE4yXg0OsyM7WdNVV4gqTxPXitVsS2NDnEOzt3URotZrfbCpiDy/66EIgmCABYOpd1Y3/z6668LAAAAAACz/O61FwAAAAAAcNq48QQAAAAATMWNJwAAAABgKm48AQAAAABTceMJAAAAAJiKG08AAAAAwFTceAIAAAAApuLGEwAAAAAw1R+O+WV/+ctffh2nf/11Nbn87nfr++D//ve/q+lvvvnm4N+H5qWffffuXfR+nX9Cf4fS73bL4ubXWXZ9b7pend///vfl/KrvTr8r5X5r9d7O/rEsy/KnP/2pN4NJ/vznP69Wgm6///znP6vpZL3oZ49Zk8tS11G17Zfl+bLrvFxNv2ZN6ud1mybreeuadL/VLVt3n6jstUb/9re/ledRnb6/v19N//3vf//69+Pj4+o1t6+59e3qyKnO8el5UWv26uqqnP7pp59W0//6179ePG9XUyo5Lx56vTr+uG3m1mN63E1qVpfNnV/0HKHf9cc//nGXNfrXv/61rNGZdZTOu1NHWkM//vjjavrf//53+d1uX3TrIamjpIYOTafnps41QLr9u3U006Ea5T+eAAAAAICpuPEEAAAAAEx11KG2APZt5lC7P/xhfbhJh7akr1fDcNzwMn3dDelJ11O17OlwJF2v3aFy3eGSCbfe3LLPHo4PAAC2w388AQAAAABTceMJAAAAAJiKG08AAAAAwFRkPAF8pY/d1sehO2NmL80Opo/a7zxyXOeV5k/T704ypfreqq3Db/lu3aa6nvX1cTu6R+87SQ730HT3+4E9SI+F6etbzus1M+DYn6TtXKp7zZB8Fq+HszgAAAAAYCpuPAEAAAAAU3HjCQAAAACYiowngK++/fbb1bRmIZMMhubxXOZC3+++W7n+l2OOU+ftMp+ae0yzJ7osVZYx7U3p3q+/TSUZT7f907xYtw8nfTyfZ4B1ndze3q6mx+3rtofL1KY5quT44batOx7osv/zn/8svzvJp+nxwdEac7+t09O424tZ11ua20t68eqxRtdrNzP4WnT7pln2kVuf3WOwm5/uD7/88svXv+/u7sp5ue92z1ZQSR2lNaS6dVSt5617lrs62hv+4wkAAAAAmIobTwAAAADAVNx4AgAAAACm2vdAYABHpRlPzXfc39+/eF7d3pfp/GfOS7Mlrrdmp99kmm3dWpUn6fYv3bp/4Tn29XR5Y61RzXhW6yzNf7nPp6+PtOaU1kmaT316eiqXrfrtLhurr19cXJTf7Wo+2Q7d3K3bRpofczWePAfgrWXV/p9uNrpzzNfPumVxx5Nq+2puOt2X0mxjUkfpMyG6/WqT396tIbeN3DMrXtv5nbUBAAAAAEfFjScAAAAAYKp9/f8VR7f18MfOEJGtl2Wmt7SsCR0y9u7du9W0DtnQIafj8Li01YUb+tId9jcOKdKhKTrEWIcfuZYj6ZBSt6zVvJVr1dId9jV+Pp23GwLUHXrrhmOeIvco/Z9++unF80qP1+l+7doKVfuP269VOqTQvT8ZOufqompRlH7XS74/kQ5Rdr+l+ryb94cPH1bTev55K7qtN5J4g5u3a6eV7nvj/NKoQzr8tVNH6Xd1r+lcHY3L445F6XlVf+ve64j/eAIAAAAApuLGEwAAAAAwFTeeAAAAAICpjprxdDkpleQc9L3Hfnzw+P1unLp79Hrn8eTpsik3Tl3Xq3t/+tjnSvro7S0fWX6qmU6ljye/vr5eTWsWUjOe4/bUek8zWyqtg+p1zTzosupj4vV3ax2k2cWqjtx+7GoozZsmj9N326Db+iX9fJojPgW6zv/xj3+spnV7Vnllt69pfb9//75ctuR4vizZ9jtm7nFZ8uzjSNeDbgN3/ElzedXxw33W0fXgllXXe5IJ/OWXX8rveqv0d7k6GvcXV6NbPk/gkGr+aY4y1amjLVsUbaG6NnLPlEh/S/XsjT3gP54AAAAAgKm48QQAAAAATMWNJwAAAABgqqMGIS8uLlbTmqNK8iEuJ1llIJbl+XjuNGOhxuyCGzvucpIqzSpWmVLXL0jHhneXRddjlftL+oEder97Pc3Opj2qToHLNmqmQvtFjZ9PsyT6ft1XNCfjPl8dI/R3ak26Zdfs688//7ya7mQfXY26Xqvd/qnV62kvxa17irrjyzm4v79fTd/e3q6mXY+3cV93x3vX39bpHAO2znRqjafPXkiybm7e3f22up7pZtlcZlz3Gfdbq+92x0m3f+6V/o5uHSVc/at0m4x1lJxzD81bzawj9zvTc5Vbr9W6cDWUPjPC5dHdtdOxnd+VNQAAAADgqLjxBAAAAABMxY0nAAAAAGCqo2Y8dZy7jlt+fHxcTVd5oa17OKZ9s6rx4a5Hj+uLlY7H1mWp8h9Vj63f8l3Kza+bpU2WJc35VvM/x36By7IsDw8Pq+nLy8vVtOamxn1d169mEd2+2M3YJhkxzVzosUppHzbNr+t6S/LIrp4d911uPVefd/2SXdYkrUmXu+n2DX2Lfvzxx+j91Tbq5t7TXrruvD1Ou95zLgflso56nnX5supc1c26pb173TVENW+9HklrSL8ryX13f9dbqXe3Pd06TK493DHR1ZHr46zG1/W82c0Xb1lH6b6WZjpdb81q2dw2S49lKjk+vAb+4wkAAAAAmIobTwAAAADAVNx4AgAAAACmOmrGU8cda05Kxz1rTmp07LH+ybj3JA+6LM/HX+t6cD2fkiycG6eeZrLc/FW1HtPx/2nPpzSPNNrbGPlZ3L6r/S+1j+dY0/reVJqLcfvq+HmX39KMp76u+bCbm5ulou/XbIzm8EZb5+j0u5IeYa7faZrJcceTNDN6Dp6enlbTLjdf9YV1+4LL4LtjbLr9xt/i9luXXdRlT3sndrKQaXZWpXVSZWPd7+7mqJM8mvvdVZ/vl3x+L9Je7VVeOd0+7nqwOtcsS1ZH6fE9fW5Dp47SmtPvSp9HkvTuTnrf/pb3pznsY+M/ngAAAACAqbjxBAAAAABMxY0nAAAAAGCqo2Y8v3z5sprWXJT2+auyCltnAVx+MOmlp2PkdXy2y4+5jEZn/HbaHyjtw5R+/zid9ohLext1nGOWbFl8rkGzi2PGU2tGc40uN3vMXIJ+l/Yrvb29XU1rz2HNzei05l2TnGWaB0v3Vff5cTvpNnXHxW4/snOtu0Sakx2nXQ26noBa/919dZxfmgdLz+Eu511lTNPsq8uPuc874/u37sWq3PVN57h9Kv2y0yxr0iPWbV+tye72qfKFaY1Vfb8P6dRR9xkfrk9w53rV5ce7570033ps/McTAAAAADAVN54AAAAAgKm48QQAAAAATHXUjKeOa9Z+ZFdXV6tpzUKOGTHXq0xtnU1U1fe77KqOyXcZ0PS3jOPq00yWqnojvkTSSy3NeHazbtX7XabnVLmeX5rbHPf1qn5fops/rmoyrQPd/jqt87u4uFhNa8Yz2Z/SnGSyHg69XmUCu/0JlcvhuDz73rIrx+CeAZDk8l2v3a3zYcm+rK+lxw+3ntyyVHmy7vkg3Y+TZ064rGqn1/ayPL+ecd+fPMdBp935Z69czjLJsqbP2XDbW+vI7Q/VNnPnGjfd1TkfuJ6jrid1p460htJlcXXUvU6fjf94AgAAAACm4sYTAAAAADAVN54AAAAAgKmOOoBexxlrxlMzYTo9jlvWbEq336SOmU7HwY+5BrcsaW7h+vp6Na09BZPf6sapuyyCG5uu3Dj5ZF6pNE9SZX5Opb+Y4/rjKs3zPDw8fP1b6zfpXXnodc1N6vHDfX7k9ns9vrgcna4n7QOqmR/taVxl21zusdvD2G3jKpfjjhfdfsrJ8eNcpNur6gPttldao643ZqLbjzLN/Ltzo9ZwxWXZunmx6ren3+1eT59vUeXNXE/yvWXRZkn27W6e2NV4mhdM6Lzcdbvaso6656Itnxmi0r6+rpeuTu/tvMl/PAEAAAAAU3HjCQAAAACYihtPAAAAAMBUR814urHiYz5sWZ7npMaMmOvJ5fJkri+O6vSI1M/qsmsWTuftegI+Pj5utmyz+5NVY8/de3UcvOvl6vJiSe+jrftP7ZWrK7cexnWon33//v1qWvdjt+9o7lpr3C171Y/S5bnSXKXOT3sUa81Wx8ZuH7ctsy3dHF263tyynUtdVlwWSffd8fVOf8HfIunr6fY1d/zv7vfV97v3umVLrzd0flV/2279u2XRfcT1DR1V++Ihb/XZCulxqVoPad/mpOfrsvT6vqZ5Ufd5t2xJHXVqaFny9Zzsy+7axu0/aR3trd81Z20AAAAAwFTceAIAAAAApuLGEwAAAAAw1VEznkmGYlmeZ8DGrKPmxZIeWy/hMl3JmHzXV00znPpdOv775ubm/373ofeP065fUHdMvv72pHej61fo3u+2Ufrb9jYu/jWk63DcBlqTHz58WE273rmubnTfctm2cdndvuayJW5fc3Wgxu9Le3B1c5cqyZseW5pfOkWuV6ZbJ2OduRrq9nBMs9FVtim9fkjy6Ick+VOV9qNM57fluckdL9z+1jkmdDPfb0WaD6yeR5D2Su6uw+SY0O29q7aso637/ibfrd/vnqWydS/uveE/ngAAAACAqbjxBAAAAABM9apDbZVrhzD+211bkDw9PZXzSh9frpLhbulQOW0bc3d3t5rW1gvX19eraR0upUMcx9fT4aZpe4N0ONQoHZaVcsuWPJr7VKV1UA0D0uEkOnTeDT/VobfdtiLjsrp2Sjrvd+/ela/rd7njj+7r42/ttmpQrq7UlnXQHWql66Lb7ukUpUPCquFr3eN5um9V70+Ht6t0KF3n+9wQcLcfp60Zqu/vDq1066Fbw9Vrp3Ke7dZRFQvprv90WGZSo+l3JUOOX7JsVR3M3teSmEG39VO6LOq1h7DzH08AAAAAwFTceAIAAAAApuLGEwAAAAAw1VEzno57dPKYg9LMlU5rPsxJs4zJ62mbDh23rnkQ/by2Y9Es3ZaPWt4yZ7csdSYwzfA4LjM685H1b4XLC6pkHbk60Bp2+1on/6Hfpe2ZNKP5ww8/rKY1R+0ynDqtNVvlT13GSl93x9FOexW3TTrZtGXxNeiytucg3T8Sbnu6vJnbfsn+4t7bbZ+15fkl3Q9dm7F0fuN26LTuODSdrveObtZ1L9JnaWjdVK170hp1NbtlexzVfSaA6rRMc9xxs9uWbPx8ek2e3n/svS0R//EEAAAAAEzFjScAAAAAYCpuPAEAAAAAUx0146njmtOcw5jbfHh4KOflck7Ohw8fVtPaS7MaP56Ot9a8mOtfqOtR+4Dq/O7v77/+neZ/kr5rL5H0hFKdXlgvmV/SE+pUueyJTuu+NnLbU/dz7c2b9nVNevVqxlK3r9b/p0+fVtOu57BO63r6/PnzanqsUX2vZrbTfoO6rN28yEiPu2k+LD2+aB4pzfKfgnS/V1We2H3X1r3xOsdVzfvqenD7vfvt1fHHHZu6matO/9puttUtu6v5Kouv20ydSmY7rRv3+US6fV0dVRlQt9+7fUXryOVNkzpKa6jbg9QZlz3tre3und5aNpr/eAIAAAAApuLGEwAAAAAwFTeeAAAAAICpXrWPp8tJVTlNN7Zc+/JpTkrpd+uy6Zhqfb3qR1n1aFoW3xPQ9S/U+V1dXa2mn56e/u+yOWmOcstealt/V7os55jxdPueq9mRy2vofqx5Pc1Z6rJpzlvrTDOj4zFBa0S5bKv7ba6/oX5+XK+6Tsf61fcui8/NpNmVJMety6J0PXQz5m8tyzJDNx9UvebWd3o+2DKzl2bXtP67/QrH97vrAf3dej2SfrceA9x2ql5zGWGX03PXN1WfcV1PM3tI7knau73qR7l1rtrNv6qjbt/m9DkvnTrS57R0z02Ozm/8rVoHSQ0d+nyaX31t/McTAAAAADAVN54AAAAAgKm48QQAAAAATHXUjGc6tjzJpmhOUsdEpz2+3Bhsff/4uhunrvPS73J9lJS+v+qV1c30OGl/qiRPluaN0kxQ9f40G/tWufywqnIRaTZZ36+57Jubm3Jat5FmU8ZenJofVe5Y5GpYuYznWLOaXXVcv7K076eq+j6muZit86Z7y64cQzfLXvWTSzOaad89lfR1dvu55sX0PKjXBK5fdvWMCZd7VLosbr/WZdPrm2o7dXO1aW9Gl/kcf4vr+Xmq0pqtjmtpL/X0usldT4511KmhZfFZaZXUkS6bXk+4c1H3erJaNtff1N2vvPXrUf7jCQAAAACYihtPAAAAAMBU3HgCAAAAAKY6asazOzZ9nHb9BTUToWOqlct8JsuWZq6qvNey+LHmLiM6jrN379Vt5LJtLh/g8iJb9vFU3bxqur+eAtfH0xn3D5f/S7en+vjxY/m6fn/Vu9Nt626uTuev+dNO1smtt25Ocjw+Jb2WD73f1aSbH/KebUmvXXdu0u3jjvcqqXl9r8tw67Lo6zp9fX1dfl+Vw3J5LrcN9Byv1ys6rapt6pbNHZddT2LdDjrtriEq3XPCXrjnG7geksk6S8+z7lyU1FGnhpbFXyundTTmOLWGuj3mu883GN/vjm3ps1C27vU6G//xBAAAAABMxY0nAAAAAGAqbjwBAAAAAFMdNePpxntvOQ7ZZRN13LobE530m9N56Tj09+/fr6Y1d/nDDz+spnWsepXhPDQ99l3S19JMZ/q6ywyO02l/wTT/keYqxn1kb2Pk92rMKrgMhL6uffZcnsz1G9PpcX9x+6nbz5+ensr367HOHfvG1y8vL1ev6b6nx4PHx8fy/Wk+tXq/y3indBtp7zVdb9Thtr2W3fE7zTI6nQyv+516XtU+v7ov6ft12bTOxt+e9kJMM116TeCeQVFtB7csLtPpcnjut43c9u/uX3vh1mmyzlxvTHc8SI8XSR11aujQsqTXj9V669ZQUmOHVNcrLsOty+qehdB9Hsqx8R9PAAAAAMBU3HgCAAAAAKbixhMAAAAAMNVRM55uHLLLKmr+Z+TyZPpZzXi6rIvrdzbS36XZNR1v/eHDh9X0p0+fVtNuvLfLgH3+/Pnr3w8PD+V7Nbvm8gQuA+RUvY1U2hMqfV2N27za905Zt1/dyOUalPbp1DyJW5a0z1b12bQ3XZqpGN9f9RtdFn8s6myjQ+8fc5gui5b2o9PPOy5Ldw5cr7ukZ6AeU5Pz3LL47efygVWG1+237jkNeu7SPLF+3vU3rJbF7Zdjf8FleX4s1PWi6zU5922ZAT70eXdtpMZ1kfZpfKuZT5dNd8fR6r2ut25Kz6tJHWlNJTW0LHnGM6kjXafuGt9Js7TVsVO/2x1H0/Nqt+fobPtaGgAAAADAyeHGEwAAAAAwFTeeAAAAAICpjprxVG7csY5lr8Y1p7kXzey5HKZmI6u+oDpm3mW2dF5p7saNyR9/u1unLnvgxo67TI9K8ifpOPikh+iy1HnWvY2Rn8VlB1yWqcrgpLkXpdtf9y2tYV22qseoLrfLh7hcjEr6aul6SvuX6rHN9d1z2ZUk35z2Puvmk86xr6fr4eaOe5U02+yOi25fS87p7nkDWpM67c6rnb59br1pDemzFPT6QiXHXZeFVe74oLm6tJf3eCxNe4qqt1LvaXY1eWZImuF126tTR2kNud/i9qVOHbkMpts39fihkjpyxzaX+XbH3b1noc/jahoAAAAA8Gq48QQAAAAATMWNJwAAAABgqqNmPLu976rX3Rh6tyzaD+j6+no1fXNzs5rWMdhjjkL7cGqfzjTH4Ma96/x0LPr42zQPdn9/Xy6L6vYMrH67m3eas9yyr+fex8xvpZNzcnS/1GmtMa0brVGX2ajyy643WpqTS9db9X0u+5rU+0uWNclNpb9r6z593R6Fp8jlpDQfVOUB057RqS2PJ/o7NePtsmxpTVevpdc2aQ9Bfb+ex8e60+Nm9d6XfFda02q8Nkrn9Vbr2z0bI5HWTLrO0jrqcL9lZh25HsI6L10P3TqqltWd4zWn7TKf6f3QsfEfTwAAAADAVNx4AgAAAACmOupQ285j3pdl/e9n/fd/2jojHS7y8ePH8vXx+137lPQR893HZ1ePU+8OfeoOORq5x1Fv3dLEtdSohmaeqvRx59U606EsOnz98vKynNb9QYeQ6qPT3fCUcdoNZ3fDdlNu/0n2NR1m8/j4uJpOW+IkXnuo62t//x50zpvL4oeIdb7LfXfns1qjerxwLY62HObr1kvVbm1ZnscKdBifi5no+8djq2v7oMcPbZeiLSrcedgNza3WVXq+ORdJrMzt5y6a4eqo0r2md+eqTh256+iqhpYlb5/i6mhsBeNay7ljdBpJ2Vsd8R9PAAAAAMBU3HgCAAAAAKbixhMAAAAAMNVRM55bchkI12pBH5XsPq9jpHWM9jhePB1/rb9Fv0vHjuv4b32/Tle5Ox3fr2PNXa4ufSR98rh097jrlI7pH8fcL0u93s5Vuv3GdaxZEa0xXf8///zzalqzSF++fCk/r1lHbWs01o0um+5r7rH/Lm/s9tUqJ+Uew+6OB6mkvVP6u9yxTt+v0/rb0vYrp8jVpNZNJd130nZZnZYlejx2x5O0JpOMv37eXR+41g363fp51/ZMr1/G50rovPScnWTRDi1r2vJk3B/Tdhp7awPxUulxamYbma3raFy2Tg0der87/id1pDWk1w/adkifzeLqSOtE66pqeZK2O9HvSq/L9lZH/McTAAAAADAVN54AAAAAgKm48QQAAAAATHXUjGeax6nGLbsxzTom2i2L9gPScfAuyzKO3077cqZ9sZTr21TlBVzPUZcn1WVNswrjsuqYfDdOPe0hpWPuk/1x6x6ie5X2k9L9YVzHLhOhn9XXNXuk20C3py67ZjqqrJHuey67kkoyO5oV0fWov9vVhUrzRh1p5rNzLMNh7tyVvLeT2Xffra/r8wc035X2L0zWQ8r1rnT9j/W3ur6eOj0+i0Gz7nd3d6tpd9x035Vu43G7uf3FXV/A77d6zNUso+tPmfS/3fp4vGUduRpy9wy3t7eraVdH6XV7Je3D6Xrt7u28eR5X0wAAAACAV8ONJwAAAABgKm48AQAAAABTHTXjmWYFqnHLbpy768nosgM6flvHa2sGdPy+NLdU9fs59F1OkmVxuRldFh03r30+0208crncrnSc/OhcsiZpVqDKUbmMg25vVweu361KchJpdm3rzOe4rjTb2u3TmS5L8tt0naa9FNPjMpnPPIepqnXs6r17HEyeleB6+Lnf7Y4Xnd6J7rt0WdNtpvNL8uyuH3I3P5b2qEyOJ6dSz+7c1ZHuS7r9XU7Sbe9qf+n2I9X3d+pIjx+uhvTZClpHrrd3sp+7eZ06/uMJAAAAAJiKG08AAAAAwFTceAIAAAAApjpqxlOl2YDq/VXvqEPT2rdTex1pdlHH7FdZGDcOvdNP8tB3O+MY/bQXokr7bHUyWZ2s0qHPd/qhnkr2JKXrTDO+mj8e60Y/m+YaXB7Q9YjU3ngXFxdf/9bfoXRZ05pzOSrNcY55V82apL3vHLcdqrpyPeDcNnLcsXFmL8ZT4Y5z4zZJn7Pgcpa6/Zxq+2oG3PV51u9273d5Vq3R0XgsWZY8P5qeh/X7dN2M2zzNF7r3u+c+JNdxac9Qd7x5q7asI3f8dnXk8sTffvvtanrchq6G9FymZtfRSK9V3HNc0utHt17H+bmaUm4bu7raWx3xH08AAAAAwFTceAIAAAAApuLGEwAAAAAw1VEH/rp+QjrOueo35HoLXV9fr6avrq5W05r/0vHbOi7+8fGxXNZxHHw1Jn5ZfP4r7fnU6ZPlpt16SDNCHd18VycPdi5ZMpdlTvs0jrbO62nNurxI1SNQ92v9HS7XVB0PluV5ZrzKaKU5mXS9do43LoPpvssdD1xmqHusPAe6zjR7VO1rbvvo+u72tqtyUFWv22VZlvv7+3Lenz9/Ll9Xyb6p+6nLhKe9El0NV71+NcuWbmNXgyo5jqcZ8Nk9jGdxxyX9XUkeMO0x7WrW1VH1PIR033LX/FvWkdvX9LzqrieU+63JM2nSayF3/bF1/+Wt8R9PAAAAAMBU3HgCAAAAAKbixhMAAAAAMNVRM57aSyYd1zy+X8edu3yXZpNub2/L1798+bKadlnHT58+ff1bx4pr5kKnXU4mzdVVn3d9s3TajYNPx6Krapx8Oobe5QVc/qzqpXYuGU+tUZelrvafdNu7fJibdseXcdl0v3aZC5dV1H3v7u6unH+VKXeZTpd9S/Nkbr0mxw9dT3rcdFkUd6yjj2eeq3XbIOEyvp0MuM5P563nXP1d+n59zoPmrt1v0fU4XnO4GnKvq4eHh/LzSutgzOmlGcD0POok53R3XOzsq6/Jbe/ONV/3vKn5YFcHWkfV+cCdk931xZZ1lM5br/lVeu7R40dSR2nW/q3V0b6WBgAAAABwcrjxBAAAAABMxY0nAAAAAGCqo2Y80/5CVS8914fP9Qx1mU33fl22MdPlsic6zj3tfeYkvdE0T6ZZE13P3YxVp6+n+65uT7Ck/9ipqnrnLsu268HlRV1duCyTZlnGad1XtGaV1qweX5SrG82oj79d14PL6LncZao6TqeZvq17FJ9jplOlvZhVZx26vr7p8aH6fPfc4rLSab/t6jW3X+vrer2hmXDt++v6H47L466j3LJt/dyGZJvqcfFUz7tb1pE7H6i0rqrnIWgNuX3JPTvBXaMldaQ15K67lTuHp1nqRPeYvvc64j+eAAAAAICpuPEEAAAAAEzFjScAAAAAYKqjZjxdbiHJk+lYbzeGWXNSaW4q6YOTjtd3v7ubaxrnp+PWNQeX9uxKvvuQJEfjchFpHjHJr+5tjPwsLp+sdaG5iaTHl9vP0yyjq/Hqu13GUzMTrveZU+VP0mNPNweZ9IVLj02uX1267HvrR/YaXE/ZtNfyKM2HdfOB1bkyrQOX23b9s935ZHy/Zts0o+nOo2PfzWV5fjzQaT3eXF5erqbH5XHHSXfwpWiAAAAQc0lEQVRcdec63f9Uct3mPtvNq7+WLesoPWa63GR6jNU6uri4+Pq37pfpczb0+kHrolNHWkOaB9Ua0uODvt/VUdUHXrkaSq9lXSZ0b3XEWRwAAAAAMBU3ngAAAACAqbjxBAAAAABMddSMp47ndn089f3jGGwdd66fTTNYboy0G7s+jhcfx8Avy/N8WJUdecl3OTp+fMxx6rh37dHk1oMbm65cBqgae67b341bT5fNZR+q/oWnymUBdN90vfJGae875d6v+3b1/el+qceTtGbd8WRcdtdvbOteukl2Ls1o6by7fT1dLvscuOOg21/Gdehy8zrtMlfu+QZu2cZ9P91PtUb12KT7nk5rbrPK0ul6uL29LZdFt5Fm09LrE302w7hu0h5+aT9llyHsPB/jVPr2bllHnRp6ybIo95yHcft3amhZntfJzDpKamhZfB25ukiubXV/cNemb/28x388AQAAAABTceMJAAAAAJjqqENt0/YJ1ePNt/5Xsxti6h5nXg0/0H+567/43dAUt550eEPVVsINVXPDFVPpMJ6RrnPlhh+4x8QnQwzf+tCG38q1akhaB6VDRLttiBJuyKcbGqWvu2Hf1fxcjbp2GiptcVFJWq8ckrbfSN9/Dtwx1bXLSNrjuMhKOuzXGT+fHr91aK2eB/Xc9v3336+mHx4eVtPVEFI952rrBR1Kp+f87nqr1o0bMqjrJR3unkQadNodL06l3t31o5NsEzeM1x0fOnXUqaFlmVtHnRo69N2upVrSQse1b0tby81uybg1/uMJAAAAAJiKG08AAAAAwFTceAIAAAAApjpqxtONLU+yTN1WDC7f5x6VXLU80N+h49bdeGyX4dJlv7u7K+c/jkV37VSUy746Sf7M7Q8uX5i20HHbYZze2xj51+LW2bhNXC4yfUx8t23IeAxwOeqtH1/e+bzLQbm6cesxebR/t91Buh7cdjpHegx327Oq0e5+nbYRcuey8Riuv0t/t54nXdZtbMd2aH5aV3reHls3aDZN56XfrZkud45P1pO+P22v0eWWvcrddfPpb0UnZ+/WkbtO0nm7fdEdT6q2hlpDmvnU9ifu+SSdOkrz62krwc6+mV5Xp5lOtXXNd+1raQAAAAAAJ4cbTwAAAADAVNx4AgAAAACmetWMp2YP3Djm8fW0n9zW+TF9/9hfSHsN6e92PXx0vbgeUC7TM87P9VXSZXP5saR3kXvdzcv1RnT97RzyZHmfvmqdz15/aV/g6rNbZ5nTHoRJHajkuHnodVfjVX7dzdvlhfRYp9Leu+cg6Z3blfbCc593+2Z1/HDb3tWcy77pvlh93p3D3bJ0n0dQrRt3vXBxcVEuq7uecMtWvZ48V+HQsp2q6ne69ZtuL3cdleQN0xpy15vVdx2aX1JHSd/2lyybZsY7ddStf1cne+tDz1kcAAAAADAVN54AAAAAgKm48QQAAAAATHXUjOe7d+9W0zqG2vXZGcempzkXN4Za51dlT5bl+bJX48F12VwfNl1PaR5Ejb06Xf8w97rq5gWqPp5pvsP1+ay++7e8fo5cjjbJ4KU16/KCbl+svttlV93n0+xhkrnYMmN1aDrtC5p8t6r6Hx+ydRb3FHXyyN3+tWkfz/T1UfqcBrdsel51+bSR1oyes9Neq+l2qJ6P4c6j+t3aS1F7e7vzqvstnRp9qxnP9LhYHXPT9Zf2WnbnsuqaUK97XWZf6fZ1/XHd56s8scujuvOguydwdVRlY92zEhxXc65X97HxH08AAAAAwFTceAIAAAAApuLGEwAAAAAw1VEzng8PD6tp1zdRXx/HTKd5j25vPFWNPU/zHPpdmj1Js4vVuuj20euqxt2n2QSlWYRuv7txXZ1rlkyzS1tm7tIadnnkJFuk+0Y3M9493lTzcpkq1T0WVu9P+/rqvHSb6bFu5v52KmZnvkZpXXS3R3I+SHtxa93c39+vpj9+/Pji+em8rq6uVtOa71Jpz2n9Pu3F6XoOVsum/QjT443LbY81nj4z4q0+Z8HlJmce19Ie92kPyHHa1VDae9flJN35pPoteq7RGtJrerdNdNl02auMqPsd+lnXm9ddG+0N//EEAAAAAEzFjScAAAAAYCpuPAEAAAAAUx0145lmE3Vc8/j5bm87991ufknfnXT8vhvPXfU3PTT/aty7G9ee9ifscOvJ5SS2zLId+r5zkK4zVfUIrN57aDrtB9c5JqR9tFy/sU5eVZcl7VeY/haXSd+yDtyyuf0vzZ+dg7SvYnUedZ9V3V6aqspB6bJ1s66Pj4+raZfRGmmuUXOSt7e35Xen+VR9vy570j/R1czl5eVqWp/N4bZDdR5Newa/1Qx3cg126P1Vf/NO395l8deXyTVAWkOul6Z+Pj2PJtf9T09Pq+k0F6nrUZe9qiO3DdPeuG+tJ/35XVkDAAAAAI6KG08AAAAAwFTceAIAAAAApjpqxtNJxnO7XEuaVeuOmx+n02xidwx/ots7Mc1kuPxZ9d6tx62797vejufAZe50OskWufyX2/fS3pjV9uvWmDvepHWT9PhSmjXpHsuqOtE+m64vsM6r6n+8LHk/Q83WnSOXm0uOk+kx1x3f09z8OP80q5zSutHMl/b5G/ft9Jyuklzkofd3rl/0s9oDVGvK1XySCXfHsk7/4z1Je+dWdbT1vtGto3F+uu21hj58+LCa1vODq5NOHaXPPuheEyR1pD1AXQ25/cn9lr1lpc/vyhoAAAAAcFTceAIAAAAApuLGEwAAAAAw1VEznulY9KTXnfuu7rKp6vU0s9nNoyb5snSdp/1L0+xKZ17K5X5dHrHaTnsbIz+L+526DpMsgb6m89L8j+s3l+ZRq4x4ml12vdBcb90qf+Jyku71tDdjUqPpNnHL7noC6nrUZb25uSmX5xy43HUn4+XmVfXafolOFinNqumy6m/T13X+Y15Ns8ra61J1exa791frQmvInQd1PbiMp+u3Wr33VDKdjjsfdOuomneaN3XG7etqSGnmU7OOW9ZRt8+vSutI62Ds8+nOo2lP8rdWR/zHEwAAAAAwFTeeAAAAAICpuPEEAAAAAEy1qz6ebix61evOjc/ujvfWMdk63rv6/k7u8dDnt+zh082WKPdbqvXo8qNp3yXNpqS5mnF5ziXjqToZ3zQ3qX2w0mVLjgnd/Vxp3sNlLvT94293uUfHZb47v9XNO+296Hqt6brQ3oqXl5fl/E9Relysem+mGctub02XZduyd7Ium8squnzZx48fv/6tGU/3PAHNsqXr3eW2q7xZOm9dVq057U+Y5NXO5TyaXgclzwVJr0XTGnXHj7GOtJ5dxvPTp0+radfPcss6Sp9fkUrqyNWQO8+6frh7x388AQAAAABTceMJAAAAAJiKG08AAAAAwFSvmvF0Pd6qvnzdXkRuWVSS6VRpz0CVZhOrZXOfdX3z0u/u9BdK86cu++DyA92c3ylyGb6kLlyeT7l9r9PL1+33ru9mOj/325N9Le0BNjMj7tab/k7N2Wmu1x0bv/vuu3J+56DKbB56vdq+bt/QzFa3z3OSP+vmgx133n16elpNj7ks/axmPjV7rK93nzlR1ZnrZ+z2H32/7gMuZ317e/t/5+96gLple6vSOhpfd+sk7fmo3Pbv9NbVnKPWlKsj7fvZraNK+gwK/a3u2nncBzTjqTV0d3e3mtZt5HoOq73V0b6WBgAAAABwcrjxBAAAAABM9apDbTvDzdLPpsPP3FC7alhP0hbm0OtK/y2v//JPhup226ekLU1UtS7ckDE3L9UdqlkNETpVbniya0kwrrPOMGud17LkNV49clxryA0Bc0NV3PAkHRqTHD/S79pa9Zh5HUql73VDhNzQ7Zubm9X01dVVvbBnIB1iXh3Tu3GC9HyQvF/3FXfsSc9dbtnUly9fvv797bfflu/VZdH3u3O4Ox65YX0JNzxeh0dqTevQW51+fHz8+ne6DU7lvNups7TG3BDRbh299LVDr481tCzPr22dpI7Sc3q3jZmr4bEO9Lt1Pei01mA6tHZvdcR/PAEAAAAAU3HjCQAAAACYihtPAAAAAMBUR814urHqOg5ZswZV1sh9V7eFgBvvXWXAuhks93h0l5Oqxr3rcrt17LIpaT6tWm+6LK4dinuUt3LLPn6f5lZOlWuPkuxrW0szXJoRG5dVH9Ou+3Wameo+rryqm+7j8rvzG9eFy66lrRtcS63vv/8+ev85cOempN2Ce283A6rbR2tSjd/fzXirtAVBdTzR457LxuvxRR2zlZdbTy4/qi0t9Big58rxt7t8ussjvhXd8+C4/bWG3L6kqmcd6Hctiz+Gj/t2up9W5+RD0506Suu7m+l010bj650aOvTdro72dp7kP54AAAAAgKm48QQAAAAATMWNJwAAAABgql1lPFUyLtmNedbx1i4/6PreVOO7XeYmyeAsy/Nx8W7+qtNb0W0D16/QbfNqHL7LAzm67C4bW/Vq1X6Cp8pl6HSdVb2y0v3cLUs3hz2+rscD7ZPlcjEuB+PyJdXxx+2X6bKpdLtUr6c9i92yf/78eTWtGa9uLuccJOuk29+6WwdJRiyt/27uuroG0Nfc8UR/p+7Xmvlyqt+e1rfrneled7nM6+vrr3/f3t6Wy9LdZnuRPo+gqqO0hro97bfkrqPdcztm1lH32OdUv12vbV0mc6yhZVmWu7u78rvTfeLYTqPKAQAAAAC7xY0nAAAAAGAqbjwBAAAAAFMdNePZ7ZMzcjmoNDfpVPm/Zcn68HXH1LveiTo9joPX362/w/ULUjqOvZO7cfkhleaLXE9B/S1jr8fLy8tyWU6F9j5N+/x19u2t+25Vy/74+Fh+tnus0uyJ1qxmUaq+bS4PtHUPwCTT6WrWZbY0O311dVV+n8t8noP0N1fvdxmsmd+dvj/d17o1nKw3rW+3LOlxNDn2dX93ejy5v79fTWuP5Pfv33/922Xy3HXWqTpmdj19HkonM55mW1WnjrY+L878vKsh7fPpervuvY74jycAAAAAYCpuPAEAAAAAU3HjCQAAAACY6qgZzyQXuSw+R1FJewC6ZXNjpJNx8Fv3N3R9Qqseo24MftrP1C1rJ6ui299l3VyexO1P33333de/k56y56zqJ5dmstJ9J+lnm2bbNBvt9h1dNs0yfvnyZTU9Zjx0X+tmsLoZ82r+6TbVmvz06dNqesyDvWRZyHj6OqjOZVvngXXa1ZnW0fj+NPfmzg/uvJlkp93zAdy802uh5Le7Ppzdaxt3/Eny6/rerXN5ryVd7modu+eRVDW0LPl+npy3u88fcNebW9ZRevxwdeTmn1zbJjW0LM/Po5rxVHurI/7jCQAAAACYihtPAAAAAMBU3HgCAAAAAKb6Zma/IAAAAAAA+I8nAAAAAGAqbjwBAAAAAFNx4wkAAAAAmIobTwAAAADAVNx4AgAAAACm4sYTAAAAADAVN54AAAAAgKm48QQAAAAATMWNJwAAAABgKm48AQAAAABTceMJAAAAAJiKG08AAAAAwFTceAIAAAAApuLGEwAAAAAwFTeeAAAAAICpuPEEAAAAAEzFjScAAAAAYCpuPAEAAAAAU3HjCQAAAACYihtPAAAAAMBU3HgCAAAAAKbixhMAAAAAMBU3ngAAAACAqf4HGK3+8XjlCQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_augmentation('data/nlst_train/image_roi_3d/25/1.tif', image_generator, n_rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_logits(y_pred):\n",
    "    y_pred = tf.clip_by_value(\n",
    "        y_pred, tf.keras.backend.epsilon(),\n",
    "        1 - tf.keras.backend.epsilon()\n",
    "    )\n",
    "\n",
    "    return tf.math.log(y_pred / (1 - y_pred))\n",
    "\n",
    "\n",
    "def weighted_cross_entropy(y_true, y_pred):\n",
    "    y_pred = convert_to_logits(y_pred)\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        logits=y_pred,\n",
    "        labels=y_true,\n",
    "        pos_weight=900\n",
    "    )\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# model = cnn_baseline()\n",
    "# model = cnn_baseline(input_shape=(32, 32, 1))\n",
    "model = cnn_baseline_3d(input_shape=(50, 50, 50, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 1e-5),\n",
    "#     loss=tf.keras.losses.binary_crossentropy,\n",
    "    loss=weighted_cross_entropy,\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.SpecificityAtSensitivity(.5),\n",
    "    ]\n",
    ")\n",
    "# model_checkpoint = ModelCheckpoint(MODEL_NAME, monitor='loss',verbose=0, save_best_only=True)\n",
    "# parallel_model = multi_gpu_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Epoch 1/14\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n",
      "Found 623 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1200 [============================>.] - ETA: 0s - loss: 1.3390 - acc: 0.5234 - precision: 0.2670 - recall: 0.3003 - auc: 0.5100 - specificity_at_sensitivity: 0.4972Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "Found 97 images belonging to 1 classes.\n",
      "1200/1200 [==============================] - 85s 71ms/step - loss: 1.3379 - acc: 0.5233 - precision: 0.2663 - recall: 0.3003 - auc: 0.5093 - specificity_at_sensitivity: 0.4961 - val_loss: 1.0198 - val_acc: 0.7300 - val_precision: 0.1034 - val_recall: 0.1071 - val_auc: 0.4387 - val_specificity_at_sensitivity: 0.4593\n",
      "Epoch 2/14\n",
      "1200/1200 [==============================] - 70s 58ms/step - loss: 1.3367 - acc: 0.4592 - precision: 0.2707 - recall: 0.3937 - auc: 0.5285 - specificity_at_sensitivity: 0.5333 - val_loss: 1.0154 - val_acc: 0.7600 - val_precision: 0.0952 - val_recall: 0.0690 - val_auc: 0.4752 - val_specificity_at_sensitivity: 0.4561\n",
      "Epoch 3/14\n",
      "1200/1200 [==============================] - 70s 58ms/step - loss: 1.3263 - acc: 0.5483 - precision: 0.3054 - recall: 0.3290 - auc: 0.5299 - specificity_at_sensitivity: 0.5461 - val_loss: 1.0834 - val_acc: 0.4850 - val_precision: 0.1205 - val_recall: 0.3333 - val_auc: 0.4397 - val_specificity_at_sensitivity: 0.4235\n",
      "Epoch 4/14\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 1.3481 - acc: 0.4742 - precision: 0.3049 - recall: 0.4237 - auc: 0.5353 - specificity_at_sensitivity: 0.5176 - val_loss: 1.0604 - val_acc: 0.5400 - val_precision: 0.1733 - val_recall: 0.4333 - val_auc: 0.4995 - val_specificity_at_sensitivity: 0.4235\n",
      "Epoch 5/14\n",
      "1200/1200 [==============================] - 70s 58ms/step - loss: 1.3058 - acc: 0.5558 - precision: 0.3166 - recall: 0.3543 - auc: 0.5316 - specificity_at_sensitivity: 0.5367 - val_loss: 1.0224 - val_acc: 0.6000 - val_precision: 0.1017 - val_recall: 0.2222 - val_auc: 0.4327 - val_specificity_at_sensitivity: 0.3064\n",
      "Epoch 6/14\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 1.3275 - acc: 0.5025 - precision: 0.3047 - recall: 0.3949 - auc: 0.5523 - specificity_at_sensitivity: 0.5835 - val_loss: 1.0050 - val_acc: 0.6200 - val_precision: 0.1379 - val_recall: 0.3077 - val_auc: 0.4792 - val_specificity_at_sensitivity: 0.4713\n",
      "Epoch 7/14\n",
      "1200/1200 [==============================] - 68s 57ms/step - loss: 1.3165 - acc: 0.5283 - precision: 0.3127 - recall: 0.3730 - auc: 0.5718 - specificity_at_sensitivity: 0.6243 - val_loss: 1.0498 - val_acc: 0.5000 - val_precision: 0.1205 - val_recall: 0.3704 - val_auc: 0.4443 - val_specificity_at_sensitivity: 0.3988\n",
      "Epoch 8/14\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 1.3529 - acc: 0.4858 - precision: 0.3057 - recall: 0.3981 - auc: 0.5353 - specificity_at_sensitivity: 0.5582 - val_loss: 1.0559 - val_acc: 0.5950 - val_precision: 0.1207 - val_recall: 0.2333 - val_auc: 0.4554 - val_specificity_at_sensitivity: 0.3000\n",
      "Epoch 9/14\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 1.2670 - acc: 0.6117 - precision: 0.3295 - recall: 0.3010 - auc: 0.5774 - specificity_at_sensitivity: 0.6257 - val_loss: 1.0515 - val_acc: 0.7350 - val_precision: 0.1250 - val_recall: 0.0938 - val_auc: 0.4897 - val_specificity_at_sensitivity: 0.4405\n",
      "Epoch 10/14\n",
      "1200/1200 [==============================] - 70s 58ms/step - loss: 1.3552 - acc: 0.5192 - precision: 0.3142 - recall: 0.3528 - auc: 0.5437 - specificity_at_sensitivity: 0.5767 - val_loss: 1.0605 - val_acc: 0.4850 - val_precision: 0.1294 - val_recall: 0.3793 - val_auc: 0.4691 - val_specificity_at_sensitivity: 0.5029\n",
      "Epoch 11/14\n",
      "1200/1200 [==============================] - 69s 57ms/step - loss: 1.3045 - acc: 0.5892 - precision: 0.3729 - recall: 0.3571 - auc: 0.5773 - specificity_at_sensitivity: 0.6581 - val_loss: 0.9961 - val_acc: 0.6250 - val_precision: 0.1525 - val_recall: 0.3600 - val_auc: 0.4922 - val_specificity_at_sensitivity: 0.4514\n",
      "Epoch 12/14\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 1.3330 - acc: 0.6025 - precision: 0.3614 - recall: 0.2830 - auc: 0.5514 - specificity_at_sensitivity: 0.5567 - val_loss: 1.1127 - val_acc: 0.5500 - val_precision: 0.1343 - val_recall: 0.2812 - val_auc: 0.4577 - val_specificity_at_sensitivity: 0.4107\n",
      "Epoch 13/14\n",
      "  54/1200 [>.............................] - ETA: 46s - loss: 1.1038 - acc: 0.5926 - precision: 0.3333 - recall: 0.6000 - auc: 0.6693 - specificity_at_sensitivity: 0.8864"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4d8423f79734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data= val_generator,\n",
    "    validation_steps=200,\n",
    "    steps_per_epoch=1200,\n",
    "    epochs = 12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nlst_cnn.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('nlst_cnn_0.hdf5')\n",
    "model.load_weights('nlst_cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "Ys = []\n",
    "for im in os.listdir('data/nlst_test/image_roi_3d/pkls/')[50:120]:\n",
    "    path = f'data/nlst_test/image_roi_3d/pkls/{im}'\n",
    "    with open(path, 'rb') as input_file:\n",
    "        cube, label = pkl.load(input_file)\n",
    "    cube = cube[:50][:50][:50]\n",
    "    if cube.shape[0] < 50 or cube.shape[1] < 50 or cube.shape[2] < 50:\n",
    "        pass\n",
    "    else:\n",
    "        Xs.append(np.array(cube/255).reshape(50, 50, 50, 1))\n",
    "        Ys.append(label)\n",
    "\n",
    "Xs = np.array(Xs)\n",
    "Ys = np.array(Ys)\n",
    "\n",
    "preds = model.predict(Xs)\n",
    "roc_auc_score(Ys, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
